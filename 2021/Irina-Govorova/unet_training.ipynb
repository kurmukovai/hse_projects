{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "glmeEIAUNufG"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms, models\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "import copy\n",
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import nibabel as nib\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, transforms):\n",
    "        self.root = 'BraTS2021_Training_Data/'\n",
    "        unnecessary_files = {'.DS_Store', '.ipynb_checkpoints'}\n",
    "        self.folder_mris = list(sorted(os.listdir(self.root)))\n",
    "        if self.folder_mris[0] in unnecessary_files:\n",
    "            self.folder_mris = self.folder_mris[1:]\n",
    "        self.transforms = transforms\n",
    "        self.num_slices = 40\n",
    "        self.start_slice = 30\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        # load images and masks\n",
    "        folder_idx = idx // self.num_slices\n",
    "        slice_idx = ((idx % self.num_slices) * 2) + self.start_slice\n",
    "        image_path = os.path.join(self.root, self.folder_mris[folder_idx])\n",
    "\n",
    "        image_name = self.folder_mris[folder_idx] + '_flair.nii.gz'\n",
    "        image = nib.load(os.path.join(image_path, image_name)).get_fdata()[:,:,slice_idx]\n",
    "            \n",
    "        mask_name = self.folder_mris[folder_idx] + '_' + 'seg' + '.nii.gz'\n",
    "        mask = nib.load(os.path.join(image_path, mask_name)).get_fdata()[:,:,slice_idx]\n",
    "        mask[mask > 0] = 1\n",
    "        transformed = self.transforms(image=np.array(image, dtype = np.uint8),\n",
    "                                      mask=np.array(mask, dtype = np.uint8))\n",
    "        image = transformed[\"image\"].float()\n",
    "        image /= torch.max(image)\n",
    "        mask = transformed[\"mask\"].float().unsqueeze(0)\n",
    "        return image, mask\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(len(self.folder_mris) * self.num_slices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "brE9OO5WN-x2"
   },
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': A.Compose(\n",
    "        [\n",
    "        A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.05, rotate_limit=15, p=0.3),\n",
    "        A.RandomResizedCrop(224, 224, scale=(0.8, 1.0), ratio=(0.9, 1.1), p=0.3),\n",
    "        A.Resize(224, 224),\n",
    "        A.RandomBrightnessContrast(p=0.2),\n",
    "        ToTensorV2(),\n",
    "        ]\n",
    "    ),\n",
    "    'val': A.Compose(\n",
    "        [\n",
    "        A.Resize(224, 224),\n",
    "        ToTensorV2(),\n",
    "        ]\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "41PKL4rKN-0V"
   },
   "outputs": [],
   "source": [
    "dataset_train = ImageDataset(data_transforms['train'])\n",
    "dataset_val = ImageDataset(data_transforms['val'])\n",
    "\n",
    "torch.manual_seed(123) #для воспроизводимости\n",
    "indices = torch.randperm(1251).tolist()\n",
    "t = int(0.8 * 1251)\n",
    "train_indices =  sum([(np.array((range(40)))+(i*40)).tolist() for i in indices[:t]], [])\n",
    "test_indices = sum([(np.array((range(40)))+(i*40)).tolist() for i in indices[t:]], [])\n",
    "\n",
    "dataset_train = torch.utils.data.Subset(dataset_train, train_indices)\n",
    "dataset_val = torch.utils.data.Subset(dataset_val, test_indices)\n",
    "\n",
    "\n",
    "dataloaders = {'train': torch.utils.data.DataLoader(dataset_train, batch_size=6, shuffle=True, num_workers=3),\n",
    "               'val': torch.utils.data.DataLoader(dataset_val, batch_size=6, shuffle=False, num_workers=3)}\n",
    "\n",
    "dataset_sizes = {'train': len(dataset_train), 'val': len(dataset_val)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h017uRg-N-3M"
   },
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_dice = 0.0\n",
    "\n",
    "    time_previous = time.time()\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_dice = 0.0\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in tqdm(dataloaders[phase]):\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    for i in range(len(inputs)):\n",
    "                        epoch_dice += dice_score(torch.round(outputs[i]), labels[i]).item()\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                running_loss += loss.item()\n",
    "\n",
    "                # statistics\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_dice /= dataset_sizes[phase]\n",
    "            \n",
    "            if phase == 'train':\n",
    "                scheduler.step(epoch_dice)\n",
    "\n",
    "            print('{} Loss: {:.4f} Dice: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_dice))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_dice > best_dice:\n",
    "                best_dice = epoch_dice\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                torch.save(best_model_wts, f'resunet_{epoch}.pth')\n",
    "            \n",
    "        print()\n",
    "        time_spent = time.time() - time_previous\n",
    "        time_previous = time.time()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_dice))\n",
    "    \n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, best_model_wts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X7UTkbDUN-6E"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6VVr9FWfN30v"
   },
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, padding=1):\n",
    "        super().__init__()\n",
    "        self.bn1 = nn.BatchNorm2d(in_channels)\n",
    "        self.act1 = nn.ReLU()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, padding=padding)\n",
    "\n",
    "        self.bn2 = nn.BatchNorm2d(in_channels)\n",
    "        self.act2 = nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, padding=padding)\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.bn1(x)\n",
    "        out = self.act1(out)\n",
    "        out = self.conv1(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.act2(out)\n",
    "        out = self.conv2(out)\n",
    "\n",
    "        out += identity\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResUNet(nn.Module):\n",
    "    def __init__(self, in_channels=4, out_channels=1, features=32, dropout=False, pooling_size=2):\n",
    "        super(ResUNet, self).__init__()\n",
    "\n",
    "        if dropout:\n",
    "            dropout_layer = nn.Dropout(0.1)\n",
    "        else:\n",
    "            dropout_layer = nn.Identity()\n",
    "\n",
    "        self.init_path = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, features, kernel_size=3, padding=1, bias=False),\n",
    "            nn.ReLU(),\n",
    "            ResidualBlock(features, features, kernel_size=3, padding=1),\n",
    "            ResidualBlock(features, features, kernel_size=3, padding=1),\n",
    "            ResidualBlock(features, features, kernel_size=3, padding=1)\n",
    "        )\n",
    "        self.shortcut0 = nn.Conv2d(features, features, kernel_size=1)\n",
    "\n",
    "        self.down1 = nn.Sequential(\n",
    "            nn.BatchNorm2d(features),\n",
    "            nn.Conv2d(features, features * 2, kernel_size=pooling_size, stride=pooling_size, bias=False),\n",
    "            nn.ReLU(),\n",
    "            dropout_layer,\n",
    "            ResidualBlock(features * 2, features * 2, kernel_size=3, padding=1),\n",
    "            ResidualBlock(features * 2, features * 2, kernel_size=3, padding=1),\n",
    "            ResidualBlock(features * 2, features * 2, kernel_size=3, padding=1)\n",
    "        )\n",
    "        self.shortcut1 = nn.Conv2d(features * 2, features * 2, 1)\n",
    "\n",
    "        self.down2 = nn.Sequential(\n",
    "            nn.BatchNorm2d(features * 2),\n",
    "            nn.Conv2d(features * 2, features * 4, kernel_size=pooling_size, stride=pooling_size, bias=False),\n",
    "            nn.ReLU(),\n",
    "            dropout_layer,\n",
    "            ResidualBlock(features * 4, features * 4, kernel_size=3, padding=1),\n",
    "            ResidualBlock(features * 4, features * 4, kernel_size=3, padding=1),\n",
    "            ResidualBlock(features * 4, features * 4, kernel_size=3, padding=1)\n",
    "        )\n",
    "        self.shortcut2 = nn.Conv2d(features * 4, features * 4, 1)\n",
    "\n",
    "        self.down3 = nn.Sequential(\n",
    "            nn.BatchNorm2d(features * 4),\n",
    "            nn.Conv2d(features * 4, features * 8, kernel_size=pooling_size, stride=pooling_size, bias=False),\n",
    "            nn.ReLU(),\n",
    "            dropout_layer,\n",
    "            ResidualBlock(features * 8, features * 8, kernel_size=3, padding=1),\n",
    "            ResidualBlock(features * 8, features * 8, kernel_size=3, padding=1),\n",
    "            ResidualBlock(features * 8, features * 8, kernel_size=3, padding=1),\n",
    "            dropout_layer\n",
    "        )\n",
    "\n",
    "        self.up3 = nn.Sequential(\n",
    "            ResidualBlock(features * 8, features * 8, kernel_size=3, padding=1),\n",
    "            ResidualBlock(features * 8, features * 8, kernel_size=3, padding=1),\n",
    "            ResidualBlock(features * 8, features * 8, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(features * 8),\n",
    "            nn.ConvTranspose2d(features * 8, features * 4, kernel_size=pooling_size, stride=pooling_size, bias=False),\n",
    "            nn.ReLU(),\n",
    "            dropout_layer\n",
    "        )\n",
    "\n",
    "        self.up2 = nn.Sequential(\n",
    "            ResidualBlock(features * 4, features * 4, kernel_size=3, padding=1),\n",
    "            ResidualBlock(features * 4, features * 4, kernel_size=3, padding=1),\n",
    "            ResidualBlock(features * 4, features * 4, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(features * 4),\n",
    "            nn.ConvTranspose2d(features * 4, features * 2, kernel_size=pooling_size, stride=pooling_size, bias=False),\n",
    "            nn.ReLU(),\n",
    "            dropout_layer\n",
    "        )\n",
    "\n",
    "        self.up1 = nn.Sequential(\n",
    "            ResidualBlock(features * 2, features * 2, kernel_size=3, padding=1),\n",
    "            ResidualBlock(features * 2, features * 2, kernel_size=3, padding=1),\n",
    "            ResidualBlock(features * 2, features * 2, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(features * 2),\n",
    "            nn.ConvTranspose2d(features * 2, features, kernel_size=pooling_size, stride=pooling_size, bias=False),\n",
    "            nn.ReLU(),\n",
    "            dropout_layer\n",
    "        )\n",
    "\n",
    "        self.out_path = nn.Sequential(\n",
    "            ResidualBlock(features, features, kernel_size=1, padding=0),\n",
    "            nn.BatchNorm2d(features),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(features, out_channels, kernel_size=1, padding=0),\n",
    "            nn.BatchNorm2d(out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x0 = self.init_path(x)\n",
    "        x1 = self.down1(x0)\n",
    "        x2 = self.down2(x1)\n",
    "        x3 = self.down3(x2)\n",
    "\n",
    "        x2_up = self.up3(x3)\n",
    "        x1_up = self.up2(x2_up + self.shortcut2(x2))\n",
    "        x0_up = self.up1(x1_up + self.shortcut1(x1))\n",
    "        x_out = self.out_path(x0_up + self.shortcut0(x0))\n",
    "        return torch.sigmoid(x_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C7E4Z1-PuZwe"
   },
   "outputs": [],
   "source": [
    "model = ResUNet(in_channels=1)\n",
    "model.to(device)\n",
    "model_name = \"resunet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coef_metric(pred, label):\n",
    "    intersection = 2.0 * (pred * label).sum()\n",
    "    union = pred.sum() + label.sum()\n",
    "    if pred.sum() == 0 and label.sum() == 0:\n",
    "        return 1.\n",
    "    return intersection / union\n",
    "\n",
    "def dice_coef_loss(pred, label):\n",
    "    smooth = 1.0\n",
    "    intersection = 2.0 * (pred * label).sum() + smooth\n",
    "    union = pred.sum() + label.sum() + smooth\n",
    "    return 1 - (intersection / union)\n",
    "\n",
    "def bce_dice_loss(pred, label):\n",
    "    dice_loss = dice_coef_loss(pred, label)\n",
    "    bce_loss = nn.BCELoss()(pred, label)\n",
    "    return dice_loss + bce_loss\n",
    "\n",
    "def train_loop(model, loader, loss_func):\n",
    "    model.train()\n",
    "    train_losses = []\n",
    "    train_dices = []\n",
    "    \n",
    "    for image, mask in tqdm(loader):\n",
    "        image = image.to(device)\n",
    "        mask = mask.to(device)\n",
    "        outputs = model(image)\n",
    "        out_cut = np.copy(outputs.data.cpu().numpy())\n",
    "        out_cut[np.nonzero(out_cut < 0.5)] = 0.0\n",
    "        out_cut[np.nonzero(out_cut >= 0.5)] = 1.0            \n",
    "\n",
    "        dice = dice_coef_metric(out_cut, mask.data.cpu().numpy())\n",
    "        loss = loss_func(outputs, mask)\n",
    "        train_losses.append(loss.item())\n",
    "        train_dices.append(dice)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "    return train_dices, train_losses\n",
    "\n",
    "def eval_loop(model, loader, loss_func, epoch, training=True):\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    val_dice = 0\n",
    "    with torch.no_grad():\n",
    "        for step, (image, mask) in tqdm(enumerate(loader)):\n",
    "            image = image.to(device)\n",
    "            mask = mask.to(device)\n",
    "    \n",
    "            outputs = model(image)\n",
    "            loss = loss_func(outputs, mask)\n",
    "            \n",
    "            out_cut = np.copy(outputs.data.cpu().numpy())\n",
    "            out_cut[np.nonzero(out_cut < 0.5)] = 0.0\n",
    "            out_cut[np.nonzero(out_cut >= 0.5)] = 1.0\n",
    "            dice = dice_coef_metric(out_cut, mask.data.cpu().numpy())\n",
    "            \n",
    "            val_loss += loss\n",
    "            val_dice += dice\n",
    "        \n",
    "        val_mean_dice = val_dice / step\n",
    "        val_mean_loss = val_loss / step\n",
    "        \n",
    "        best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        torch.save(best_model_wts, f'resunet_{epoch}.pth')      \n",
    "        \n",
    "        if training:\n",
    "            scheduler.step(val_mean_dice)\n",
    "        \n",
    "    return val_mean_dice, val_mean_loss\n",
    "\n",
    "def train_model(train_loader, val_loader, loss_func, optimizer, scheduler, num_epochs):\n",
    "    train_loss_history = []\n",
    "    train_dice_history = []\n",
    "    val_loss_history = []\n",
    "    val_dice_history = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        train_dices, train_losses = train_loop(model, train_loader, loss_func)\n",
    "        train_mean_dice = np.array(train_dices).mean()\n",
    "        train_mean_loss = np.array(train_losses).mean()\n",
    "        val_mean_dice, val_mean_loss = eval_loop(model, val_loader, loss_func, epoch)\n",
    "        \n",
    "        train_loss_history.append(np.array(train_losses).mean())\n",
    "        train_dice_history.append(np.array(train_dices).mean())\n",
    "        val_loss_history.append(val_mean_loss)\n",
    "        val_dice_history.append(val_mean_dice)\n",
    "        \n",
    "        print('Epoch: {}/{} |  Train Loss: {:.3f}, Val Loss: {:.3f}, Train DICE: {:.3f}, Val DICE: {:.3f}'.format(epoch+1, num_epochs,\n",
    "                                                                                                                 train_mean_loss,\n",
    "                                                                                                                 val_mean_loss,\n",
    "                                                                                                                 train_mean_dice,\n",
    "                                                                                                                 val_mean_dice))\n",
    "        \n",
    "\n",
    "    return train_loss_history, train_dice_history, val_loss_history, val_dice_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', patience=3)\n",
    "train_loss_history, train_dice_history, val_loss_history, val_dice_history = train_model(dataloaders['train'],\n",
    "                                                                                         dataloaders['val'],\n",
    "                                                                                         bce_dice_loss, optimizer,\n",
    "                                                                                         scheduler, 20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "unet_training.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
