{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15345142",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms, models\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import os\n",
    "from PIL import Image, ImageOps\n",
    "import numpy as np\n",
    "import time\n",
    "import copy\n",
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import nibabel as nib\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import sklearn.covariance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1843cb11",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, padding=1):\n",
    "        super().__init__()\n",
    "        self.bn1 = nn.BatchNorm2d(in_channels)\n",
    "        self.act1 = nn.ReLU()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, padding=padding)\n",
    "\n",
    "        self.bn2 = nn.BatchNorm2d(in_channels)\n",
    "        self.act2 = nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, padding=padding)\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.bn1(x)\n",
    "        out = self.act1(out)\n",
    "        out = self.conv1(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.act2(out)\n",
    "        out = self.conv2(out)\n",
    "\n",
    "        out += identity\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResUNet(nn.Module):\n",
    "    def __init__(self, in_channels=4, out_channels=1, features=32, dropout=False, pooling_size=2):\n",
    "        super(ResUNet, self).__init__()\n",
    "\n",
    "        if dropout:\n",
    "            dropout_layer = nn.Dropout(0.1)\n",
    "        else:\n",
    "            dropout_layer = nn.Identity()\n",
    "\n",
    "        self.init_path = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, features, kernel_size=3, padding=1, bias=False),\n",
    "            nn.ReLU(),\n",
    "            ResidualBlock(features, features, kernel_size=3, padding=1),\n",
    "            ResidualBlock(features, features, kernel_size=3, padding=1),\n",
    "            ResidualBlock(features, features, kernel_size=3, padding=1)\n",
    "        )\n",
    "        self.shortcut0 = nn.Conv2d(features, features, kernel_size=1)\n",
    "\n",
    "        self.down1 = nn.Sequential(\n",
    "            nn.BatchNorm2d(features),\n",
    "            nn.Conv2d(features, features * 2, kernel_size=pooling_size, stride=pooling_size, bias=False),\n",
    "            nn.ReLU(),\n",
    "            dropout_layer,\n",
    "            ResidualBlock(features * 2, features * 2, kernel_size=3, padding=1),\n",
    "            ResidualBlock(features * 2, features * 2, kernel_size=3, padding=1),\n",
    "            ResidualBlock(features * 2, features * 2, kernel_size=3, padding=1)\n",
    "        )\n",
    "        self.shortcut1 = nn.Conv2d(features * 2, features * 2, 1)\n",
    "\n",
    "        self.down2 = nn.Sequential(\n",
    "            nn.BatchNorm2d(features * 2),\n",
    "            nn.Conv2d(features * 2, features * 4, kernel_size=pooling_size, stride=pooling_size, bias=False),\n",
    "            nn.ReLU(),\n",
    "            dropout_layer,\n",
    "            ResidualBlock(features * 4, features * 4, kernel_size=3, padding=1),\n",
    "            ResidualBlock(features * 4, features * 4, kernel_size=3, padding=1),\n",
    "            ResidualBlock(features * 4, features * 4, kernel_size=3, padding=1)\n",
    "        )\n",
    "        self.shortcut2 = nn.Conv2d(features * 4, features * 4, 1)\n",
    "\n",
    "        self.down3 = nn.Sequential(\n",
    "            nn.BatchNorm2d(features * 4),\n",
    "            nn.Conv2d(features * 4, features * 8, kernel_size=pooling_size, stride=pooling_size, bias=False),\n",
    "            nn.ReLU(),\n",
    "            dropout_layer,\n",
    "            ResidualBlock(features * 8, features * 8, kernel_size=3, padding=1),\n",
    "            ResidualBlock(features * 8, features * 8, kernel_size=3, padding=1),\n",
    "            ResidualBlock(features * 8, features * 8, kernel_size=3, padding=1),\n",
    "            dropout_layer\n",
    "        )\n",
    "\n",
    "        self.up3 = nn.Sequential(\n",
    "            ResidualBlock(features * 8, features * 8, kernel_size=3, padding=1),\n",
    "            ResidualBlock(features * 8, features * 8, kernel_size=3, padding=1),\n",
    "            ResidualBlock(features * 8, features * 8, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(features * 8),\n",
    "            nn.ConvTranspose2d(features * 8, features * 4, kernel_size=pooling_size, stride=pooling_size, bias=False),\n",
    "            nn.ReLU(),\n",
    "            dropout_layer\n",
    "        )\n",
    "\n",
    "        self.up2 = nn.Sequential(\n",
    "            ResidualBlock(features * 4, features * 4, kernel_size=3, padding=1),\n",
    "            ResidualBlock(features * 4, features * 4, kernel_size=3, padding=1),\n",
    "            ResidualBlock(features * 4, features * 4, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(features * 4),\n",
    "            nn.ConvTranspose2d(features * 4, features * 2, kernel_size=pooling_size, stride=pooling_size, bias=False),\n",
    "            nn.ReLU(),\n",
    "            dropout_layer\n",
    "        )\n",
    "\n",
    "        self.up1 = nn.Sequential(\n",
    "            ResidualBlock(features * 2, features * 2, kernel_size=3, padding=1),\n",
    "            ResidualBlock(features * 2, features * 2, kernel_size=3, padding=1),\n",
    "            ResidualBlock(features * 2, features * 2, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(features * 2),\n",
    "            nn.ConvTranspose2d(features * 2, features, kernel_size=pooling_size, stride=pooling_size, bias=False),\n",
    "            nn.ReLU(),\n",
    "            dropout_layer\n",
    "        )\n",
    "\n",
    "        self.out_path = nn.Sequential(\n",
    "            ResidualBlock(features, features, kernel_size=1, padding=0),\n",
    "            nn.BatchNorm2d(features),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(features, out_channels, kernel_size=1, padding=0),\n",
    "            nn.BatchNorm2d(out_channels)\n",
    "        )\n",
    "    \n",
    "    # function to extract the multiple features\n",
    "    def feature_list(self, x):\n",
    "        out_list = []\n",
    "        \n",
    "        x0 = self.init_path(x)\n",
    "        out_list.append(x0)\n",
    "        x1 = self.down1(x0)\n",
    "        out_list.append(x1)\n",
    "        x2 = self.down2(x1)\n",
    "        out_list.append(x2)\n",
    "        x3 = self.down3(x2)\n",
    "        out_list.append(x3)\n",
    "        x2_up = self.up3(x3)\n",
    "        out_list.append(x2_up)\n",
    "        x1_up = self.up2(x2_up + self.shortcut2(x2))\n",
    "        out_list.append(x1_up)\n",
    "        x0_up = self.up1(x1_up + self.shortcut1(x1))\n",
    "        out_list.append(x0_up)\n",
    "        x_out = self.out_path(x0_up + self.shortcut0(x0))\n",
    "        out_list.append(x_out)\n",
    "        \n",
    "        return x_out, out_list\n",
    "\n",
    "    def forward(self, x):\n",
    "        x0 = self.init_path(x)\n",
    "        x1 = self.down1(x0)\n",
    "        x2 = self.down2(x1)\n",
    "        x3 = self.down3(x2)\n",
    "\n",
    "        x2_up = self.up3(x3)\n",
    "        x1_up = self.up2(x2_up + self.shortcut2(x2))\n",
    "        x0_up = self.up1(x1_up + self.shortcut1(x1))\n",
    "        x_out = self.out_path(x0_up + self.shortcut0(x0))\n",
    "        return torch.sigmoid(x_out)\n",
    "\n",
    "    def intermediate_forward(self, x):\n",
    "        x0 = self.init_path(x)\n",
    "        x1 = self.down1(x0)\n",
    "        x2 = self.down2(x1)\n",
    "        x3 = self.down3(x2)\n",
    "        \n",
    "        return x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d0b904",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89290848",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResUNet(in_channels=1)\n",
    "model.load_state_dict(torch.load('resunet_9.pth'))\n",
    "model.to(device)\n",
    "model_name = \"resunet\"\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3e2d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self):\n",
    "        self.root = 'BraTS2021_Training_Data/'\n",
    "        unnecessary_files = {'.DS_Store', '.ipynb_checkpoints'}\n",
    "        self.folder_mris = list(sorted(os.listdir(self.root)))\n",
    "        if self.folder_mris[0] in unnecessary_files:\n",
    "            self.folder_mris = self.folder_mris[1:]\n",
    "        self.num_slices = 25\n",
    "        self.start_slice = 20\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        folder_idx = idx // self.num_slices\n",
    "        slice_idx = ((idx % self.num_slices) * 4) + self.start_slice\n",
    "        image_path = os.path.join(self.root, self.folder_mris[folder_idx])\n",
    "\n",
    "        image_types = [\"flair\", \"t1\", \"t1ce\", \"t2\"]\n",
    "        image = np.zeros((1, 240, 240))\n",
    "        for i, image_type in enumerate(image_types):\n",
    "            image_name = self.folder_mris[folder_idx] + '_' + image_type + '.nii.gz'\n",
    "            image[i] = nib.load(os.path.join(image_path, image_name)).get_fdata()[:,:,slice_idx]\n",
    "            break\n",
    "\n",
    "        mask_name = self.folder_mris[folder_idx] + '_' + 'seg' + '.nii.gz'\n",
    "        mask = np.zeros((1, 240, 240))\n",
    "        mask[0] = nib.load(os.path.join(image_path, mask_name)).get_fdata()[:,:,slice_idx]\n",
    "        mask[mask > 0] = 1\n",
    "        image = torch.as_tensor(image, dtype=torch.float)\n",
    "        \n",
    "        mask = torch.as_tensor(mask, dtype=torch.float)\n",
    "        \n",
    "        return image, mask\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(len(self.folder_mris) * self.num_slices)\n",
    "\n",
    "dataset_train = ImageDataset()\n",
    "dataset_val = ImageDataset()\n",
    "\n",
    "torch.manual_seed(123) #для воспроизводимости\n",
    "indices = torch.randperm(1251).tolist()\n",
    "t = int(0.8 * 1251)\n",
    "train_indices =  sum([(np.array((range(25)))+(i*25)).tolist() for i in indices[:t]], [])\n",
    "test_indices = sum([(np.array((range(25)))+(i*25)).tolist() for i in indices[t:]], [])\n",
    "\n",
    "dataset_train = torch.utils.data.Subset(dataset_train, train_indices)\n",
    "dataset_val = torch.utils.data.Subset(dataset_val, test_indices)\n",
    "\n",
    "\n",
    "dataloaders = {'train': torch.utils.data.DataLoader(dataset_train, batch_size=6, shuffle=True, num_workers=3),\n",
    "               'val': torch.utils.data.DataLoader(dataset_val, batch_size=6, shuffle=False, num_workers=3)}\n",
    "\n",
    "dataset_sizes = {'train': len(dataset_train), 'val': len(dataset_val)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c666349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# собираю эмбеддинги из обучащего датасета для трейна PCA\n",
    "\n",
    "all_embeddings = []\n",
    "with torch.no_grad():\n",
    "    for i, (image, _) in tqdm(enumerate(dataloaders['train'])):\n",
    "        image = image.to(device)\n",
    "        output_emb = model.intermediate_forward(image).cpu().numpy()\n",
    "        for output_emb_sep in output_emb:\n",
    "            all_embeddings.append(output_emb_sep.flatten())\n",
    "        if i == 2000:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d52216",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import IsolationForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394561d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c5f660",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_embeddings = np.array(all_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85aac48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_emb = pca.fit_transform(all_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0bd7ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "del all_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ce0d0c",
   "metadata": {},
   "source": [
    "## Isolation Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ceb4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = IsolationForest().fit(pca_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1014554",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"pca_unet.pkl\", 'wb') as f: \n",
    "    pickle.dump(pca, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc37604",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_embeddings_val = []\n",
    "folder_list = []\n",
    "slice_num_list = []\n",
    "with torch.no_grad():\n",
    "    for i, (image, _) in tqdm(enumerate(dataloaders['val'])):\n",
    "        image = image.to(device)\n",
    "        output_emb = model.intermediate_forward(image).cpu().numpy()\n",
    "        for output_emb_sep in output_emb:\n",
    "            all_embeddings_val.append(output_emb_sep.flatten())\n",
    "            \n",
    "all_embeddings_val = np.array(all_embeddings_val)\n",
    "pca_emb_val = pca.transform(all_embeddings_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055275bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087027a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "del all_embeddings_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831eedce",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = clf.predict(pca_emb_val)\n",
    "acc = len(np.where(prediction==1)[0]) / len(prediction)\n",
    "print(\"accuracy\", acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c2fdfe",
   "metadata": {},
   "source": [
    "## LOF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e69e071",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "clf2 = LocalOutlierFactor(n_neighbors=5, novelty=True)\n",
    "clf2.fit(pca_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759a64bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = clf2.predict(pca_emb_val)\n",
    "acc = len(np.where(prediction==1)[0]) / len(prediction)\n",
    "print(\"accuracy\", acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0f1103",
   "metadata": {},
   "source": [
    "## OneClassSVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b6accc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import OneClassSVM\n",
    "clf3 = OneClassSVM(degree=10).fit(pca_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38743063",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = clf3.predict(pca_emb_val)\n",
    "acc = len(np.where(prediction==1)[0]) / len(prediction)\n",
    "print(\"accuracy\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec84c8a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
