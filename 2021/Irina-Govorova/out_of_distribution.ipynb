{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15345142",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms, models\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import os\n",
    "from PIL import Image, ImageOps\n",
    "import numpy as np\n",
    "import time\n",
    "import copy\n",
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import nibabel as nib\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import sklearn.covariance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1843cb11",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, padding=1):\n",
    "        super().__init__()\n",
    "        self.bn1 = nn.BatchNorm2d(in_channels)\n",
    "        self.act1 = nn.ReLU()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, padding=padding)\n",
    "\n",
    "        self.bn2 = nn.BatchNorm2d(in_channels)\n",
    "        self.act2 = nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, padding=padding)\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.bn1(x)\n",
    "        out = self.act1(out)\n",
    "        out = self.conv1(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.act2(out)\n",
    "        out = self.conv2(out)\n",
    "\n",
    "        out += identity\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResUNet(nn.Module):\n",
    "    def __init__(self, in_channels=4, out_channels=1, features=32, dropout=False, pooling_size=2):\n",
    "        super(ResUNet, self).__init__()\n",
    "\n",
    "        if dropout:\n",
    "            dropout_layer = nn.Dropout(0.1)\n",
    "        else:\n",
    "            dropout_layer = nn.Identity()\n",
    "\n",
    "        self.init_path = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, features, kernel_size=3, padding=1, bias=False),\n",
    "            nn.ReLU(),\n",
    "            ResidualBlock(features, features, kernel_size=3, padding=1),\n",
    "            ResidualBlock(features, features, kernel_size=3, padding=1),\n",
    "            ResidualBlock(features, features, kernel_size=3, padding=1)\n",
    "        )\n",
    "        self.shortcut0 = nn.Conv2d(features, features, kernel_size=1)\n",
    "\n",
    "        self.down1 = nn.Sequential(\n",
    "            nn.BatchNorm2d(features),\n",
    "            nn.Conv2d(features, features * 2, kernel_size=pooling_size, stride=pooling_size, bias=False),\n",
    "            nn.ReLU(),\n",
    "            dropout_layer,\n",
    "            ResidualBlock(features * 2, features * 2, kernel_size=3, padding=1),\n",
    "            ResidualBlock(features * 2, features * 2, kernel_size=3, padding=1),\n",
    "            ResidualBlock(features * 2, features * 2, kernel_size=3, padding=1)\n",
    "        )\n",
    "        self.shortcut1 = nn.Conv2d(features * 2, features * 2, 1)\n",
    "\n",
    "        self.down2 = nn.Sequential(\n",
    "            nn.BatchNorm2d(features * 2),\n",
    "            nn.Conv2d(features * 2, features * 4, kernel_size=pooling_size, stride=pooling_size, bias=False),\n",
    "            nn.ReLU(),\n",
    "            dropout_layer,\n",
    "            ResidualBlock(features * 4, features * 4, kernel_size=3, padding=1),\n",
    "            ResidualBlock(features * 4, features * 4, kernel_size=3, padding=1),\n",
    "            ResidualBlock(features * 4, features * 4, kernel_size=3, padding=1)\n",
    "        )\n",
    "        self.shortcut2 = nn.Conv2d(features * 4, features * 4, 1)\n",
    "\n",
    "        self.down3 = nn.Sequential(\n",
    "            nn.BatchNorm2d(features * 4),\n",
    "            nn.Conv2d(features * 4, features * 8, kernel_size=pooling_size, stride=pooling_size, bias=False),\n",
    "            nn.ReLU(),\n",
    "            dropout_layer,\n",
    "            ResidualBlock(features * 8, features * 8, kernel_size=3, padding=1),\n",
    "            ResidualBlock(features * 8, features * 8, kernel_size=3, padding=1),\n",
    "            ResidualBlock(features * 8, features * 8, kernel_size=3, padding=1),\n",
    "            dropout_layer\n",
    "        )\n",
    "\n",
    "        self.up3 = nn.Sequential(\n",
    "            ResidualBlock(features * 8, features * 8, kernel_size=3, padding=1),\n",
    "            ResidualBlock(features * 8, features * 8, kernel_size=3, padding=1),\n",
    "            ResidualBlock(features * 8, features * 8, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(features * 8),\n",
    "            nn.ConvTranspose2d(features * 8, features * 4, kernel_size=pooling_size, stride=pooling_size, bias=False),\n",
    "            nn.ReLU(),\n",
    "            dropout_layer\n",
    "        )\n",
    "\n",
    "        self.up2 = nn.Sequential(\n",
    "            ResidualBlock(features * 4, features * 4, kernel_size=3, padding=1),\n",
    "            ResidualBlock(features * 4, features * 4, kernel_size=3, padding=1),\n",
    "            ResidualBlock(features * 4, features * 4, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(features * 4),\n",
    "            nn.ConvTranspose2d(features * 4, features * 2, kernel_size=pooling_size, stride=pooling_size, bias=False),\n",
    "            nn.ReLU(),\n",
    "            dropout_layer\n",
    "        )\n",
    "\n",
    "        self.up1 = nn.Sequential(\n",
    "            ResidualBlock(features * 2, features * 2, kernel_size=3, padding=1),\n",
    "            ResidualBlock(features * 2, features * 2, kernel_size=3, padding=1),\n",
    "            ResidualBlock(features * 2, features * 2, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(features * 2),\n",
    "            nn.ConvTranspose2d(features * 2, features, kernel_size=pooling_size, stride=pooling_size, bias=False),\n",
    "            nn.ReLU(),\n",
    "            dropout_layer\n",
    "        )\n",
    "\n",
    "        self.out_path = nn.Sequential(\n",
    "            ResidualBlock(features, features, kernel_size=1, padding=0),\n",
    "            nn.BatchNorm2d(features),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(features, out_channels, kernel_size=1, padding=0),\n",
    "            nn.BatchNorm2d(out_channels)\n",
    "        )\n",
    "    \n",
    "    # function to extract the multiple features\n",
    "    def feature_list(self, x):\n",
    "        out_list = []\n",
    "        \n",
    "        x0 = self.init_path(x)\n",
    "        out_list.append(x0)\n",
    "        x1 = self.down1(x0)\n",
    "        out_list.append(x1)\n",
    "        x2 = self.down2(x1)\n",
    "        out_list.append(x2)\n",
    "        x3 = self.down3(x2)\n",
    "        out_list.append(x3)\n",
    "        x2_up = self.up3(x3)\n",
    "        out_list.append(x2_up)\n",
    "        x1_up = self.up2(x2_up + self.shortcut2(x2))\n",
    "        out_list.append(x1_up)\n",
    "        x0_up = self.up1(x1_up + self.shortcut1(x1))\n",
    "        out_list.append(x0_up)\n",
    "        x_out = self.out_path(x0_up + self.shortcut0(x0))\n",
    "        out_list.append(x_out)\n",
    "        \n",
    "        return x_out, out_list\n",
    "\n",
    "    def forward(self, x):\n",
    "        x0 = self.init_path(x)\n",
    "        x1 = self.down1(x0)\n",
    "        x2 = self.down2(x1)\n",
    "        x3 = self.down3(x2)\n",
    "\n",
    "        x2_up = self.up3(x3)\n",
    "        x1_up = self.up2(x2_up + self.shortcut2(x2))\n",
    "        x0_up = self.up1(x1_up + self.shortcut1(x1))\n",
    "        x_out = self.out_path(x0_up + self.shortcut0(x0))\n",
    "        return torch.sigmoid(x_out)\n",
    "\n",
    "    def intermediate_forward(self, x):\n",
    "        x0 = self.init_path(x)\n",
    "        x1 = self.down1(x0)\n",
    "        x2 = self.down2(x1)\n",
    "        x3 = self.down3(x2)\n",
    "        \n",
    "        return x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61d0b904",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89290848",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResUNet(\n",
       "  (init_path): Sequential(\n",
       "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (1): ReLU()\n",
       "    (2): ResidualBlock(\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU()\n",
       "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act2): ReLU()\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (3): ResidualBlock(\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU()\n",
       "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act2): ReLU()\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (4): ResidualBlock(\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU()\n",
       "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act2): ReLU()\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (shortcut0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (down1): Sequential(\n",
       "    (0): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (1): Conv2d(32, 64, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
       "    (2): ReLU()\n",
       "    (3): Identity()\n",
       "    (4): ResidualBlock(\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU()\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act2): ReLU()\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (5): ResidualBlock(\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU()\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act2): ReLU()\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (6): ResidualBlock(\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU()\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act2): ReLU()\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (shortcut1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (down2): Sequential(\n",
       "    (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (1): Conv2d(64, 128, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
       "    (2): ReLU()\n",
       "    (3): Identity()\n",
       "    (4): ResidualBlock(\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU()\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act2): ReLU()\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (5): ResidualBlock(\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU()\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act2): ReLU()\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (6): ResidualBlock(\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU()\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act2): ReLU()\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (shortcut2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (down3): Sequential(\n",
       "    (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (1): Conv2d(128, 256, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
       "    (2): ReLU()\n",
       "    (3): Identity()\n",
       "    (4): ResidualBlock(\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU()\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act2): ReLU()\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (5): ResidualBlock(\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU()\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act2): ReLU()\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (6): ResidualBlock(\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU()\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act2): ReLU()\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (7): Identity()\n",
       "  )\n",
       "  (up3): Sequential(\n",
       "    (0): ResidualBlock(\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU()\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act2): ReLU()\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (1): ResidualBlock(\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU()\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act2): ReLU()\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (2): ResidualBlock(\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU()\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act2): ReLU()\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (4): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
       "    (5): ReLU()\n",
       "    (6): Identity()\n",
       "  )\n",
       "  (up2): Sequential(\n",
       "    (0): ResidualBlock(\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU()\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act2): ReLU()\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (1): ResidualBlock(\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU()\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act2): ReLU()\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (2): ResidualBlock(\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU()\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act2): ReLU()\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (4): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
       "    (5): ReLU()\n",
       "    (6): Identity()\n",
       "  )\n",
       "  (up1): Sequential(\n",
       "    (0): ResidualBlock(\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU()\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act2): ReLU()\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (1): ResidualBlock(\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU()\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act2): ReLU()\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (2): ResidualBlock(\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU()\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act2): ReLU()\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (4): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
       "    (5): ReLU()\n",
       "    (6): Identity()\n",
       "  )\n",
       "  (out_path): Sequential(\n",
       "    (0): ResidualBlock(\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU()\n",
       "      (conv1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act2): ReLU()\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (4): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ResUNet(in_channels=1)\n",
    "model.load_state_dict(torch.load('resunet_10.pth'))\n",
    "model.to(device)\n",
    "model_name = \"resunet\"\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac3e2d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self):\n",
    "        self.root = 'BraTS2021_Training_Data/'\n",
    "        unnecessary_files = {'.DS_Store', '.ipynb_checkpoints'}\n",
    "        self.folder_mris = list(sorted(os.listdir(self.root)))\n",
    "        if self.folder_mris[0] in unnecessary_files:\n",
    "            self.folder_mris = self.folder_mris[1:]\n",
    "        self.num_slices = 25\n",
    "        self.start_slice = 20\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        folder_idx = idx // self.num_slices\n",
    "        slice_idx = ((idx % self.num_slices) * 4) + self.start_slice\n",
    "        image_path = os.path.join(self.root, self.folder_mris[folder_idx])\n",
    "\n",
    "        image_types = [\"flair\", \"t1\", \"t1ce\", \"t2\"]\n",
    "        image = np.zeros((1, 240, 240))\n",
    "        for i, image_type in enumerate(image_types):\n",
    "            image_name = self.folder_mris[folder_idx] + '_' + image_type + '.nii.gz'\n",
    "            image[i] = nib.load(os.path.join(image_path, image_name)).get_fdata()[:,:,slice_idx]\n",
    "            break\n",
    "\n",
    "        image = image / np.max(image) * 255\n",
    "        mask_name = self.folder_mris[folder_idx] + '_' + 'seg' + '.nii.gz'\n",
    "        mask = nib.load(os.path.join(image_path, mask_name)).get_fdata()[:,:,slice_idx]\n",
    "        mask[mask > 0] = 1\n",
    "        transformed = self.transforms(image=np.array(image, dtype = np.uint8),\n",
    "                                      mask=np.array(mask, dtype = np.uint8))\n",
    "        image = transformed[\"image\"].float()\n",
    "        image /= 255.\n",
    "        mask = transformed[\"mask\"].float().unsqueeze(0)\n",
    "        return image, mask\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(len(self.folder_mris) * self.num_slices)\n",
    "    \n",
    "    \n",
    "data_transforms = {\n",
    "    'train': A.Compose(\n",
    "        [\n",
    "        A.RandomResizedCrop(224, 224, scale=(0.8, 1.0), ratio=(0.9, 1.1), p=0.3),\n",
    "        A.Resize(224, 224),\n",
    "        ToTensorV2(),\n",
    "        ]\n",
    "    ),\n",
    "    'val': A.Compose(\n",
    "        [\n",
    "        A.Resize(224, 224),\n",
    "        ToTensorV2(),\n",
    "        ]\n",
    "    )\n",
    "}\n",
    "\n",
    "\n",
    "dataset_train = ImageDataset(data_transforms['train'])\n",
    "dataset_val = ImageDataset(data_transforms['val'])\n",
    "\n",
    "torch.manual_seed(123) #для воспроизводимости\n",
    "indices = torch.randperm(1251).tolist()\n",
    "t = int(0.8 * 1251)\n",
    "train_indices =  sum([(np.array((range(40)))+(i*40)).tolist() for i in indices[:t]], [])\n",
    "test_indices = sum([(np.array((range(40)))+(i*40)).tolist() for i in indices[t:]], [])\n",
    "\n",
    "dataset_train = torch.utils.data.Subset(dataset_train, train_indices)\n",
    "dataset_val = torch.utils.data.Subset(dataset_val, test_indices)\n",
    "\n",
    "\n",
    "dataloaders = {'train': torch.utils.data.DataLoader(dataset_train, batch_size=6, shuffle=True, num_workers=3),\n",
    "               'val': torch.utils.data.DataLoader(dataset_val, batch_size=6, shuffle=False, num_workers=3)}\n",
    "\n",
    "dataset_sizes = {'train': len(dataset_train), 'val': len(dataset_val)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c666349",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2000it [10:03,  3.31it/s]\n"
     ]
    }
   ],
   "source": [
    "# собираю эмбеддинги из обучащего датасета для трейна PCA\n",
    "\n",
    "all_embeddings = []\n",
    "with torch.no_grad():\n",
    "    for i, (image, _) in tqdm(enumerate(dataloaders['train'])):\n",
    "        image = image.to(device)\n",
    "        output_emb = model.intermediate_forward(image).cpu().numpy()\n",
    "        for output_emb_sep in output_emb:\n",
    "            all_embeddings.append(output_emb_sep.flatten())\n",
    "        if i == 2000:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58d52216",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import IsolationForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "394561d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "99c5f660",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_embeddings = np.array(all_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "85aac48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_emb = pca.fit_transform(all_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a0bd7ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "del all_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9077826",
   "metadata": {},
   "source": [
    "## Isolation Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f3ceb4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = IsolationForest().fit(pca_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d1014554",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"pca_unet.pkl\", 'wb') as f: \n",
    "    pickle.dump(pca, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bcc37604",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1046it [04:50,  3.60it/s]\n"
     ]
    }
   ],
   "source": [
    "all_embeddings_val = []\n",
    "folder_list = []\n",
    "slice_num_list = []\n",
    "with torch.no_grad():\n",
    "    for i, (image, _) in tqdm(enumerate(dataloaders['val'])):\n",
    "        image = image.to(device)\n",
    "        output_emb = model.intermediate_forward(image).cpu().numpy()\n",
    "        for output_emb_sep in output_emb:\n",
    "            all_embeddings_val.append(output_emb_sep.flatten())\n",
    "            \n",
    "all_embeddings_val = np.array(all_embeddings_val)\n",
    "pca_emb_val = pca.transform(all_embeddings_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "055275bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9931263901598868"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "087027a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "del all_embeddings_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "831eedce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.9260557768924302\n"
     ]
    }
   ],
   "source": [
    "prediction = clf.predict(pca_emb_val)\n",
    "acc = len(np.where(prediction==1)[0]) / len(prediction)\n",
    "print(\"accuracy\", acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c2fdfe",
   "metadata": {},
   "source": [
    "## LOF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5e69e071",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LocalOutlierFactor(n_neighbors=5, novelty=True)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "clf2 = LocalOutlierFactor(n_neighbors=5, novelty=True)\n",
    "clf2.fit(pca_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "759a64bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.9692430278884462\n"
     ]
    }
   ],
   "source": [
    "prediction = clf2.predict(pca_emb_val)\n",
    "acc = len(np.where(prediction==1)[0]) / len(prediction)\n",
    "print(\"accuracy\", acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66fcf16",
   "metadata": {},
   "source": [
    "## OneClassSVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "10b6accc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import OneClassSVM\n",
    "clf3 = OneClassSVM(degree=10).fit(pca_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "38743063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.48717131474103587\n"
     ]
    }
   ],
   "source": [
    "prediction = clf3.predict(pca_emb_val)\n",
    "acc = len(np.where(prediction==1)[0]) / len(prediction)\n",
    "print(\"accuracy\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b299944d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1b5b34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
